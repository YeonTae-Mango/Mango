#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# AI/New_User/generate_user_profiles.py

import json
import pandas as pd
from datetime import datetime
from pathlib import Path
import sys
import os

# AI/New_Userì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬(AI)ë¥¼ sys.pathì— ì¶”ê°€
current_dir = Path(__file__).parent  # AI/New_User
ai_dir = current_dir.parent           # AI
sys.path.append(str(ai_dir))

from Analyze.infer_cosine import infer_profile

def load_trainset_data():
    """trainset.csv íŒŒì¼ ë¡œë“œ"""
    # AI/New_Userì—ì„œ AI/Bankingìœ¼ë¡œ ê°€ëŠ” ê²½ë¡œ
    csv_path = ai_dir / "Banking" / "trainset.csv"
    if not csv_path.exists():
        raise FileNotFoundError(f"trainset.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
    
    df = pd.read_csv(csv_path, encoding='utf-8')
    print(f"trainset.csv ë¡œë“œ ì™„ë£Œ: {len(df)}ê±´")
    return df

def load_users_data():
    """users_for_entity_named_fixed_gender.csv íŒŒì¼ ë¡œë“œ"""
    # AI/New_Userì—ì„œ AI/Bankingìœ¼ë¡œ ê°€ëŠ” ê²½ë¡œ
    csv_path = ai_dir / "Banking" / "users_for_entity_named_fixed_gender.csv"
    if not csv_path.exists():
        raise FileNotFoundError(f"users íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
    
    df = pd.read_csv(csv_path, encoding='utf-8')
    print(f"users íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ëª…")
    return df

def convert_trainset_to_mock_format(trainset_df, users_df):
    """trainsetê³¼ users ë°ì´í„°ë¥¼ mock.json í˜•íƒœë¡œ ë³€í™˜"""
    user_data_list = []
    
    # ìœ ì €ë³„ë¡œ ê·¸ë£¹í™”
    unique_users = sorted(trainset_df['ìœ ì €ì•„ì´ë””'].unique())
    print(f"ì´ {len(unique_users)}ëª…ì˜ ìœ ì € ë°ì´í„° ë³€í™˜ ì‹œì‘...")
    
    for user_id in unique_users:
        user_payments = trainset_df[trainset_df['ìœ ì €ì•„ì´ë””'] == user_id].copy()
        
        # í•´ë‹¹ ìœ ì € ì •ë³´ ì°¾ê¸°
        user_info = users_df[users_df['user_id'] == user_id]
        if len(user_info) == 0:
            print(f"Warning: ìœ ì € {user_id} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ê¸°ë³¸ ì •ë³´ë¡œ ìƒì„±
            gender = "ë‚¨ì" if user_id <= 50 else "ì—¬ì"
            age = 30
            birth_date = "1993-01-01"
        else:
            user_info = user_info.iloc[0]
            gender = str(user_info['gender'])
            
            # ìƒë…„ì›”ì¼ì—ì„œ ë‚˜ì´ ê³„ì‚°
            try:
                birth_date = pd.to_datetime(user_info['birth_date'])
                age = datetime.now().year - birth_date.year
                if datetime.now().month < birth_date.month or \
                   (datetime.now().month == birth_date.month and datetime.now().day < birth_date.day):
                    age -= 1
                birth_date = str(birth_date)[:10]
            except:
                age = 30
                birth_date = "1993-01-01"
        
        # ê²°ì œ ë°ì´í„°ë¥¼ mock.json í˜•íƒœë¡œ ë³€í™˜
        payments_list = []
        for _, payment in user_payments.iterrows():
            payment_dict = {
                "user_id": int(payment['ìœ ì €ì•„ì´ë””']),
                "payment_time": str(payment['ê²°ì œì‹œì ']),
                "category": str(payment['ëŒ€ë¶„ë¥˜']),
                "subcategory": str(payment['ì†Œë¶„ë¥˜']),
                "payment_id": str(payment['ê²°ì œë²ˆí˜¸']),
                "payment_amount": int(payment['ê²°ì œê¸ˆì•¡'])
            }
            payments_list.append(payment_dict)
        
        # ê²°ì œ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        payments_list.sort(key=lambda x: x['payment_time'])
        
        # mock.json í˜•íƒœë¡œ êµ¬ì„±
        user_mock_data = {
            "user": {
                "birthdate": birth_date,
                "gender": gender,
                "age": age,
                "user_id": int(user_id)
            },
            "period": {
                "months": 6,
                "end_date": str(payments_list[-1]['payment_time'][:10]) if payments_list else "2025-09-16"
            },
            "count": len(payments_list),
            "payments": payments_list
        }
        
        user_data_list.append(user_mock_data)
        
        if user_id % 10 == 0:  # 10ëª…ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
            print(f"ìœ ì € {user_id} ë³€í™˜ ì™„ë£Œ (ì§„í–‰ë¥ : {user_id}/{len(unique_users)})")
    
    return user_data_list

def generate_user_profile_analysis(user_mock_data):
    """ë‹¨ì¼ ìœ ì €ì˜ í”„ë¡œí•„ ë¶„ì„ ìˆ˜í–‰"""
    try:
        # artifacts í´ë” ê²½ë¡œ (AI/New_Userì—ì„œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ artifactsë¡œ)
        emb_path = ai_dir.parent / "artifacts" / "small_embeddings.npy"
        
        # infer_profile í•¨ìˆ˜ í˜¸ì¶œ
        analysis = infer_profile(
            user_mock_data, 
            emb_path=str(emb_path),
            tau=0.7, 
            include_missing_zero=True
        )
        
        # to_preferred_shape í•¨ìˆ˜ì™€ ìœ ì‚¬í•œ í˜•íƒœë¡œ ë³€í™˜
        # ëŒ€í‘œìœ í˜• í™•ë¥  ì •ê·œí™”
        types = [{"name": t["name"], "prob": float(t.get("prob", 0.0))}
                 for t in analysis.get("ëŒ€í‘œìœ í˜•", [])]
        s = sum(t["prob"] for t in types) or 1.0
        for t in types:
            t["prob"] = round(t["prob"]/s, 2)
        
        # í‚¤ì›Œë“œ ì „ì²´
        keywords = [{"name": k["name"], "score": round(float(k.get("score", 0.0)), 2)}
                   for k in analysis.get("í‚¤ì›Œë“œ", [])]
        
        # ìŒì‹ ì„¹ì…˜
        by_big = analysis.get("ëŒ€ë¶„ë¥˜ìƒì„¸", {})
        food_list = by_big.get("ìŒì‹", [])
        food = [{"name": x["name"], "score": round(float(x.get("score", 0.0)), 2)}
               for x in food_list]
        
        result = {
            "user_id": user_mock_data["user"]["user_id"],
            "ëŒ€í‘œìœ í˜•": types,
            "í‚¤ì›Œë“œ": keywords,
            "ìŒì‹": food
        }
        
        return result
        
    except Exception as e:
        print(f"ìœ ì € {user_mock_data['user']['user_id']} ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("=== ì‚¬ìš©ì í”„ë¡œí•„ ë¶„ì„ ì‹œì‘ ===")
        print(f"ì‘ì—… ë””ë ‰í† ë¦¬: {Path.cwd()}")
        print(f"ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜: {Path(__file__).parent}")
        print(f"AI ë””ë ‰í† ë¦¬: {ai_dir}")
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("\n1. ë°ì´í„° ë¡œë“œ ì¤‘...")
        trainset_df = load_trainset_data()
        users_df = load_users_data()
        
        # 2. mock.json í˜•íƒœë¡œ ë³€í™˜
        print("\n2. ë°ì´í„° ë³€í™˜ ì¤‘...")
        user_mock_list = convert_trainset_to_mock_format(trainset_df, users_df)
        print(f"ì´ {len(user_mock_list)}ëª…ì˜ ìœ ì € ë°ì´í„° ë³€í™˜ ì™„ë£Œ")
        
        # 3. ê° ìœ ì €ë³„ í”„ë¡œí•„ ë¶„ì„
        print("\n3. í”„ë¡œí•„ ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
        user_profiles = []
        
        for i, user_mock_data in enumerate(user_mock_list, 1):
            user_id = user_mock_data['user']['user_id']
            
            if i % 10 == 1:  # ì²˜ìŒê³¼ 10ì˜ ë°°ìˆ˜ë§ˆë‹¤ ì¶œë ¥
                print(f"[{i}/{len(user_mock_list)}] ìœ ì € {user_id} ë¶„ì„ ì¤‘...")
            
            profile_result = generate_user_profile_analysis(user_mock_data)
            if profile_result:
                user_profiles.append(profile_result)
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if i % 20 == 0:
                print(f"ì§„í–‰ë¥ : {i}/{len(user_mock_list)} ({i/len(user_mock_list)*100:.1f}%)")
        
        # 4. ê²°ê³¼ ì €ì¥
        print(f"\n4. ê²°ê³¼ ì €ì¥ ì¤‘...")
        output_path = current_dir / "user_category_data.json"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(user_profiles, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š ì´ ë¶„ì„ëœ ìœ ì €: {len(user_profiles)}ëª…")
        
        # ìƒ˜í”Œ ì¶œë ¥
        if user_profiles:
            print(f"\n=== ìƒ˜í”Œ ë°ì´í„° (ìœ ì € {user_profiles[0]['user_id']}) ===")
            sample = user_profiles[0]
            print(f"ëŒ€í‘œìœ í˜• ìˆ˜: {len(sample['ëŒ€í‘œìœ í˜•'])}")
            print(f"í‚¤ì›Œë“œ ìˆ˜: {len(sample['í‚¤ì›Œë“œ'])}")
            print(f"ìŒì‹ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(sample['ìŒì‹'])}")
            
            print("\nìƒìœ„ 3ê°œ ëŒ€í‘œìœ í˜•:")
            for i, type_info in enumerate(sample['ëŒ€í‘œìœ í˜•'][:3], 1):
                print(f"  {i}. {type_info['name']}: {type_info['prob']}")
            
            print("\nìƒìœ„ 5ê°œ í‚¤ì›Œë“œ:")
            for i, keyword in enumerate(sample['í‚¤ì›Œë“œ'][:5], 1):
                print(f"  {i}. {keyword['name']}: {keyword['score']}")
            
            print("\nìŒì‹ ì¹´í…Œê³ ë¦¬:")
            for i, food_item in enumerate(sample['ìŒì‹'], 1):
                print(f"  {i}. {food_item['name']}: {food_item['score']}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()